import React from "react";
import Navbar from "@/components/Navbar";
import ImageCarousel from "@/components/ImageCarousel";
import NewsSection from "@/components/NewsSection";
import AgentFutureNews from "@/components/AgentFutureNews";

const AgentFuture = () => {
  return (
    <div className="min-h-screen flex flex-col">
      <Navbar />
      <ImageCarousel />

      <main className="flex-1 bg-gray-50">
        <div className="container mx-auto py-8 px-4">
          <h1 className="text-3xl font-bold mb-8 text-center">Agentic AI based Software of the future: from Scale to Trust</h1>
          <p className="text-center text-lg mb-12" style={{ marginTop: "-20px"}}>
            A research project funded by the National Research Foundation, Singapore
          </p>

          <img src="/public/agent_workflow_diagram.png" alt="Agent Future" className="w-full h-auto mb-8 rounded-lg shadow-md" />
          <p className="text-center text-sm text-gray-500 mb-12" style={{ marginTop: "-20px" }}><i>Figure: An envisioned workflow for future software development with agentic AI.</i></p>

          <h2 className="text-2xl font-semibold mb-4">Overview</h2>
          <p className="mb-6">
            The practice of software is significantly shifting due to the rapid development and improvement of generative artificial intelligence (GenAI). In particular, large language models (LLMs) have shown significant promise, especially when deployed as LLM agents, i.e., when LLMs are combined with external tools to aid decision-making and action-taking. The unprecedented pace of change makes it ever more important to understand how software engineering will change, and what impact this will have on industry.

This research program aims to examine how future software engineering is likely to shift from <b>scale to trust</b> as agents become prevalent. Prior software engineering research emphasized how a large number of generally trustworthy human developers could coordinate to make large software (scale). However, we foresee a change in which often untrustworthy but fast agents will write a large proportion of future software, making it important to research how to increase trust. More specifically, we posit that it is important to engender trust in software artifacts such as code automatically generated by AI agents.
          </p>

          <h2 className="text-2xl font-semibold mb-4">Goal</h2>
          <p className="mb-6">
            In pursuit of the vision of shifting research from scale to trust, we will research trust-building technology that would automatically (1) improve the quality of agent-generated software, and (2) generate additional artifacts to enhance the trust developers can place in agent-generated software. We propose to research a unification of specialized agents to a single unified software agent that can handle all tasks, and a mechanism for validating AI-generated software comprehensively so that AI artifacts come with degrees of assurance. Overall, an AI workflow for software systems of the future would be delivered; this workflow would be deployed at enterprises to not only speed development, but make it trustworthy.
          </p>

          
          <AgentFutureNews />
        </div>
      </main>
      

      <footer className="bg-nus-blue text-white py-6">
        <div className="container mx-auto px-4 text-center">
          <p>
            Â© {new Date().getFullYear()} SPARTAN - National University of
            Singapore
          </p>
          <p className="text-sm mt-2">
            <a
              href="https://enterprise.nus.edu.sg"
              className="hover:text-gray-200"
              target="_blank"
              rel="noopener noreferrer"
            >
              National University of Singapore (NUS) Enterprise
            </a>{" "}
            i3 Building Level 2, 21 Heng Mui Keng Terrace, Singapore 119613, Republic of Singapore.
          </p>
        </div>
      </footer>
    </div>
  );
};

export default AgentFuture;